{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f90163",
   "metadata": {},
   "source": [
    "**1. Скачивание данных.**\n",
    "\n",
    "Скачиваем отзывы о театральных постановках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dfc1bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b06388d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f29d0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537ff4b",
   "metadata": {},
   "source": [
    "Создаём dataframe для наших отзывов (мне удобнее, когда промежуточный результат будет именно в таком формате)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "16ddc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.DataFrame({'grade': [], 'review': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e737e",
   "metadata": {},
   "source": [
    "**Что делают следующие функции:**\n",
    "\n",
    "-parse_one_performance скачивает отзывы со страницы спектакля, учитывая общую оценку (отрицательные — 1-2 звезды и меньше, положительные — 4-5 звёзд).\n",
    "\n",
    "-parse_performance_page_block достаёт ссылку на новость, смотрит на оценку спектакля, если она ниже трёх с половиной, то ищем отрицательные, в ином случае положительные.\n",
    "\n",
    "-get_nth_page разбивает страницу на спектакли, объединяет две предыдущие функции.\n",
    "-run_all прогоняет по номерам страниц и записывает все отзывы с их оценкой в dataframe.\n",
    "\n",
    "Ещё стоит отметить, что выбирала я только те отзывы, в которых больше 10 слов. Они должны быть более репрезентативными.\n",
    "\n",
    "Если что-то не получалось, то ошибки записывала в текстовый файл (хотя особо информации это не несёт).\n",
    "\n",
    "Не знала точно, сколько получится выкачать отзывов, поэтому взяла с запасом 60 страниц. Так скачала по 110 отзывов каждого типа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4b17ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_performance_page_block(one_block):\n",
    "    block = {}\n",
    "    a = one_block.find('a')\n",
    "    block['href'] = a.attrs['href']\n",
    "    grade = one_block.find('div', {'class': 'cifra'}).text\n",
    "    if float(grade) <= 3.5:\n",
    "        block['grade'] = 'negative'\n",
    "    else:\n",
    "        block['grade'] = 'positive' \n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6bbb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_performance(block):\n",
    "    url_one = block['href']\n",
    "    req = session.get(url_one, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    reviews = soup.find_all('div', {'class': 'element-item 1'})\n",
    "    \n",
    "    reviews_text = []\n",
    "    for i in reviews:\n",
    "        rating = i.find('span', itemprop='reviewRating')\n",
    "        rating_grade = rating.find(itemprop='ratingValue') #сколько звёзд поставил пользователь\n",
    "        if block['grade'] == 'negative':\n",
    "            if int(str(rating_grade)[15]) <= 2:\n",
    "                review = i.find('div', {'class': 'text mytext'}).text\n",
    "                if len(word_tokenize(review)) >= 10:\n",
    "                    reviews_text.append(review)\n",
    "        else:\n",
    "            if int(str(rating_grade)[15]) > 3:\n",
    "                review = i.find('div', {'class': 'text mytext'}).text\n",
    "                if len(word_tokenize(review)) >= 10:\n",
    "                    reviews_text.append(review)\n",
    "        \n",
    "        block['reviews'] = reviews_text\n",
    "        return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53d55ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_page(page_number):\n",
    "\n",
    "    url = f'https://teatrow.ru/msk/page/{page_number}/'\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    performances = soup.find_all('div', {'class': 'box_in block_info'})\n",
    "\n",
    "    blocks = []\n",
    "    for n in performances:\n",
    "        try:\n",
    "            blocks.append(parse_performance_page_block(n))\n",
    "        except Exception as e:\n",
    "            with open('Errors.txt', 'a', encoding='utf-8') as f:\n",
    "                error = ' '.join([str(e), 'Ссылка на страницу:', url, '\\n'])\n",
    "                f.write(error)\n",
    "\n",
    "\n",
    "    result = []\n",
    "    for b in blocks:  \n",
    "        try:\n",
    "            res = parse_one_performance(b)\n",
    "            result.append(res)\n",
    "        except Exception as e:\n",
    "            with open('Errors.txt', 'a', encoding='utf-8') as f:\n",
    "                error = ' '.join([str(e), 'Ссылка на страницу:', url, '\\n'])\n",
    "                f.write(error)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78835291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(n_pages):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i in tqdm(range(n_pages)):\n",
    "        try: #на странице 50, кажется, у меня возникла проблема с тем, чтобы получить ссылку поэтому я решила и сюда добавить try except\n",
    "            blocks = get_nth_page(i+1)\n",
    "            for block in blocks:\n",
    "                if block['grade'] == 'positive' and positive <=110:\n",
    "                    for i in block['reviews']:\n",
    "                        df_review.loc[len(df_review.index)] = [block['grade'], i]\n",
    "                        positive+=1\n",
    "                elif block['grade'] == 'negative' and negative <=110:\n",
    "                    for i in block['reviews']:\n",
    "                        df_review.loc[len(df_review.index)] = [block['grade'], i]\n",
    "                        negative+=1\n",
    "        except Exception as e:\n",
    "            with open('Errors.txt', 'a', encoding='utf-8') as f:\n",
    "                error = ' '.join([str(e), 'проблема с сылкой на страницу', '\\n'])\n",
    "                f.write(error)\n",
    "            \n",
    "    return df_review   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee63e324",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce8cfff627b4e348511b529fb193d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Замечательный мюзикл. Прекрасно провели время....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>пойду снова в третий раз !!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Как будто попал 1990 лет назад или 33 год наше...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Спектакль очень понравился! Замечательная музы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>Я просто полностью погрузился в атмосферу спек...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>negative</td>\n",
       "      <td>От Стриндберга осталось чуть больше половины. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>negative</td>\n",
       "      <td>Выскажу сугубо свое мнение: тем, кто смотрел г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>negative</td>\n",
       "      <td>были 30.09.2019. замечательно! на дам-чиповск...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>negative</td>\n",
       "      <td>Ушли после первого акта. Юмор дешёвого стендап...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>negative</td>\n",
       "      <td>Не смотря на самоотверженную игру актёров, спе...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        grade                                             review\n",
       "0    positive  Замечательный мюзикл. Прекрасно провели время....\n",
       "1    positive                     пойду снова в третий раз !!!!!\n",
       "2    positive  Как будто попал 1990 лет назад или 33 год наше...\n",
       "3    positive  Спектакль очень понравился! Замечательная музы...\n",
       "4    positive  Я просто полностью погрузился в атмосферу спек...\n",
       "..        ...                                                ...\n",
       "217  negative  От Стриндберга осталось чуть больше половины. ...\n",
       "218  negative  Выскажу сугубо свое мнение: тем, кто смотрел г...\n",
       "219  negative   были 30.09.2019. замечательно! на дам-чиповск...\n",
       "220  negative  Ушли после первого акта. Юмор дешёвого стендап...\n",
       "221  negative  Не смотря на самоотверженную игру актёров, спе...\n",
       "\n",
       "[222 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f4b4c",
   "metadata": {},
   "source": [
    "Чтобы вновь не тратить много времени на скачивание, загрузим всё в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b08c4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.to_csv (r'df_review.csv', index= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4764bfe",
   "metadata": {},
   "source": [
    "Когда я ставила ограничение на 10 слов, я не думала, что может стоять много знаков препинания (!), которые могут посчитать за один токен. В результате есть несколько (совсем мало) отзывов, где слов мало, но много знаков препинания. Так как таких отзывов всё-таки малое количество, то я их решила не убирать и оставить всё как есть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d191d",
   "metadata": {},
   "source": [
    "**2. Токенизируйте слова, приведите их к нижнему регистру и к начальной форме.**\n",
    "\n",
    "Для того, чтобы привести слова к начальной форме, воспользуюсь pymorphy. На этом же шаге я решила избавиться от стоп-слов, так как они не влияют на тональность текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4eba118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_csv('df_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0d3426aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "sw = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b00e0",
   "metadata": {},
   "source": [
    "Выбираем случайные отзывы для теста и удаляем по индексу эти строки из основной таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d4375cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pos = df_review[(df_review['grade'] == 'positive')]\n",
    "df_pos_test = df_pos.sample(n=10)\n",
    "\n",
    "df_neg = df_review[(df_review['grade'] == 'negative')]\n",
    "df_neg_test = df_neg.sample(n=10) \n",
    "\n",
    "df_test = pd.concat([df_neg_test, df_pos_test])\n",
    "\n",
    "index = df_test.index.tolist ()\n",
    "df_review.drop(labels = index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd4d0b",
   "metadata": {},
   "source": [
    "Здесь я прохожусь по каждому отзыву, смотрю какой он и токенизирую, привожу слова к нижнему регистру и начальной форме. Тут же удаляю стоп-слова и убираю пунктуацию, так как нам нужны множества *слов*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "784bb374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1068bfd72cc487abcf34c41953d69b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_negative_reviews = []\n",
    "words_positive_reviews = []\n",
    "\n",
    "for i, row in tqdm(df_review.iterrows()): #просто понимать, идёт ли обработка отзывов или нет\n",
    "    if row['grade'] == 'negative':\n",
    "        work_review = [w.lower() for w in word_tokenize(row['review']) if w.isalpha()]\n",
    "        for token in work_review:\n",
    "            word_morph = morph.parse(token)\n",
    "            if word_morph[0].normal_form not in sw:\n",
    "                words_negative_reviews.append(word_morph[0].normal_form)\n",
    "    else:\n",
    "        work_review = [w.lower() for w in word_tokenize(row['review']) if w.isalpha()]\n",
    "        for token in work_review:\n",
    "            word_morph = morph.parse(token)\n",
    "            if word_morph[0].normal_form not in sw:\n",
    "                words_positive_reviews.append(word_morph[0].normal_form) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60285eb8",
   "metadata": {},
   "source": [
    "**3. Составьте 2 множества - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных.**\n",
    "\n",
    "Тут я исключаю те слова, что встречаются по одному разу лишь и создаю два множества и беру из каждого всё, кроме их пересечения (чтобы были только уникальные для каждого типа отзывов слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "77499b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_dicts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3f20fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqlist = Counter()\n",
    "for word in words_negative_reviews:\n",
    "    freqlist[word] += 1\n",
    "dict_negative_reviews = dict(freqlist)\n",
    "both_dicts['negative'] = dict_negative_reviews\n",
    "\n",
    "freqlist = Counter()\n",
    "for word in words_positive_reviews:\n",
    "    freqlist[word] += 1\n",
    "dict_positive_reviews = dict(freqlist)\n",
    "both_dicts['positive'] = dict_positive_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f7688e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_neg = []\n",
    "\n",
    "for element in both_dicts['negative']:\n",
    "    if dict_negative_reviews[element] > 2:\n",
    "        most_freq_neg.append(element)\n",
    "\n",
    "most_freq_pos = []\n",
    "for element in both_dicts['positive']:\n",
    "    if dict_positive_reviews[element] > 2:\n",
    "        most_freq_pos.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8e228ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = set(most_freq_neg)\n",
    "pos = set(most_freq_pos)\n",
    "neg_pos = set.intersection(neg, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7a3cd6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg.symmetric_difference_update(neg_pos)\n",
    "pos.symmetric_difference_update(neg_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce4597",
   "metadata": {},
   "source": [
    "**4. Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy.**\n",
    "\n",
    "Эта функция определяет тональность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1ced47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_or_neg(set_pos, set_neg, review_input):\n",
    "\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for word in word_tokenize(review_input):\n",
    "        word_morph = morph.parse(word)\n",
    "        if word_morph[0].normal_form in set_pos:\n",
    "            positive+= 1\n",
    "        if word_morph[0].normal_form in set_neg:\n",
    "            negative+= 1\n",
    "            \n",
    "    if positive > negative:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf7de5",
   "metadata": {},
   "source": [
    "А эта считает качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9636f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tone_detect(set_pos, set_neg, df_test):\n",
    "    results = []\n",
    "    origin = []\n",
    "    \n",
    "    for i, row in df_test.iterrows():\n",
    "        predicted_tone = pos_or_neg(set_pos, set_neg, row['review'])\n",
    "        results.append(predicted_tone)\n",
    "\n",
    "        origin.append(row['grade'])\n",
    "\n",
    "    print(f'result: {accuracy_score(results, origin)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b1c263ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.65\n"
     ]
    }
   ],
   "source": [
    "test_tone_detect(pos, neg, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aabb8f",
   "metadata": {},
   "source": [
    "Да, итог получился не прям хорошим, но это больше половины!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4905c7f",
   "metadata": {},
   "source": [
    "**5. Предложите как минимум 2 способа улучшить этот алгоритм определения тональности отзыва.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ea73b",
   "metadata": {},
   "source": [
    "*Способ нумер раз-с:*\n",
    "\n",
    "Изначально, когда мы составляем тональный словарь, чем чаще встречается слово, тем больший вес ему можем дать. В тот момент, когда мы будем определять, какой же всё-таки по тональности отзыв, мы будем смотреть на вес слова и на разницу в значениях между \"положительными\" словами и \"отрицательными\". \n",
    "\n",
    "Пример: пускай слово \"ужасный\" встречается очень много раз и будет иметь вес x, а вот слово \"неплохо\" реже (вес y, x>y). Оба этих слова встречаются в рассматриваемом отзыве. Разница между количеством \"положительных\" и \"отрицательных\" слов небольшая или её вовсе нет (1 положительное и 1 отрицательное). Однако есть сильное \"отрицательное\" слово, которое перевесит в сторону отрицательной тональности. Таким образом, алгоритм будет работать чуть лучше.\n",
    "\n",
    "В качестве весов можно сделать значение Tf-Idf. Посчитаем метрику и получим матрицу, где строками будут отзывы, а столбцами слова. Суммировав все значения в одном столбце мы получим вес слова, который будет отвечать за что-то типо важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2e397631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "34e9d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    analyzer = 'word',\n",
    "    stop_words = sw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6c061217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb3b1f6fac84510a30df2befcb4d62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reviews = []\n",
    "\n",
    "for i, row in tqdm(df_review.iterrows()):\n",
    "    review_tokens = wordpunct_tokenize(row['review'])\n",
    "    review_lemmatized = \" \".join([morph.parse(item)[0].normal_form for item in review_tokens])\n",
    "    negative_reviews_preprocessed.append(review_lemmatized)\n",
    "    all_reviews.append(review_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "34adfdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tfidf = tfidf.fit_transform(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9c43c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_review = pd.DataFrame(review_tfidf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52f5c3",
   "metadata": {},
   "source": [
    "При первичной обработке у нас есть уже частотный словарь и списки. Ими мы и воспользуемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6750e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_neg = {}\n",
    "for i in most_freq_neg:\n",
    "    dict_neg[i] = matrix_review[i].sum()\n",
    "    \n",
    "dict_pos = {}\n",
    "for i in most_freq_pos:\n",
    "    dict_pos[i] = matrix_review[i].sum()\n",
    "    \n",
    "dict_tone_tfidf = {\n",
    "    'neg': dict_neg,\n",
    "    'pos': dict_pos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1eb31e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_or_neg_tfidf(dict_tone_tfidf, review_input):\n",
    "    \n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for word in word_tokenize(review_input):\n",
    "        word_morph = morph.parse(word)\n",
    "        if word_morph[0].normal_form in dict_tone_tfidf['pos']:\n",
    "            positive+= dict_tone_tfidf['pos'][word_morph[0].normal_form]\n",
    "        if word_morph[0].normal_form in dict_tone_tfidf['neg']:\n",
    "            negative+= dict_tone_tfidf['neg'][word_morph[0].normal_form]\n",
    "            \n",
    "    if positive > negative:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4ccacb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tone_detect_tfidf(dict_tone_tfidf, df_test):\n",
    "    results = []\n",
    "    origin = []\n",
    "    \n",
    "    for i, row in df_test.iterrows():\n",
    "        predicted_tone = pos_or_neg_tfidf(dict_tone_tfidf, row['review'])\n",
    "        results.append(predicted_tone)\n",
    "\n",
    "        origin.append(row['grade'])\n",
    "\n",
    "    print(f'result: {accuracy_score(results, origin)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e32e6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.7\n"
     ]
    }
   ],
   "source": [
    "test_tone_detect_tfidf(dict_tone_tfidf, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49efd6",
   "metadata": {},
   "source": [
    "Уже 0.7! На целых 5 сотых больше. На мой взгляд, это точно говорит об улучшении алгоритма!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52442e65",
   "metadata": {},
   "source": [
    "*Способ нумер два-с:*\n",
    "\n",
    "Воспользуемся семантической близостью слов. На основе наших отзывов можно построить модель в word2vec, таким образом у каждого слова будет свой вектор. Когда мы будем определять тональность отзыва и какого-то слова не будет в частотном списке слов, то мы будем смотреть на похожие слова. \n",
    "\n",
    "Пример: слово \"годный\" не встречается в частотном списке, так как встретилось лишь один раз, но мы можем найти похожие слова с помощью most_similar. Если что-то из топ-5 входит в частотный спислк, тот мы добавим балл в копилку отрицательной тональности. \n",
    "\n",
    "Тут мне кажется, можно давать 2 пункта, если слово было в частотном списке как есть и 1 пункт, если мы его отнесли к какому-то виду через поиск похожих слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bf568d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "import urllib.request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4928750",
   "metadata": {},
   "source": [
    "В предыдущем дополнении к алгоритму мы собрали все тексты в all_review. В этом же способе мы их возьмём, так как они уже приведены к нижнему региструу и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "895a1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in all_reviews:\n",
    "    sentences_in_review = sent_tokenize(review)\n",
    "    with open('reviews.txt', mode='a', encoding='utf-8') as file_result:\n",
    "        for sentence in sentences_in_review:\n",
    "            sentence_no_punct = re.sub(r'[^\\w\\s]','', sentence) \n",
    "            if sentence_no_punct != '':\n",
    "                file_result.write(sentence_no_punct+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "104d25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obuch = 'reviews.txt'\n",
    "data = gensim.models.word2vec.LineSentence(file_obuch)\n",
    "\n",
    "model_review = gensim.models.Word2Vec(data, window=5, vector_size=300, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5cf6d8",
   "metadata": {},
   "source": [
    "В первом алгоритме мы использовали уже множества \"отрицательных\" и \"положительных\" слов. Ими мы и воспользуемся сейчас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "467a8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_or_neg_word2vec(set_pos, set_neg, review_input):\n",
    "    \n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for word in word_tokenize(review_input):\n",
    "        word_morph = morph.parse(word)\n",
    "        if word_morph[0].normal_form in set_pos:\n",
    "            positive+= 2\n",
    "        elif word_morph[0].normal_form in list(model_review.wv.index_to_key):\n",
    "            sim_words = model_review.wv.most_similar(positive = [word_morph[0].normal_form], topn=5)\n",
    "            for i in sim_words:\n",
    "                if i in set_pos:\n",
    "                    positive+= 1\n",
    "             \n",
    "        if word_morph[0].normal_form in set_neg:\n",
    "            negative+= 2\n",
    "        elif word_morph[0].normal_form in list(model_review.wv.index_to_key):\n",
    "            sim_words = model_review.wv.most_similar(positive = [word_morph[0].normal_form], topn=5)\n",
    "            for i in sim_words:\n",
    "                if i in set_neg:\n",
    "                    negative+= 1\n",
    "            \n",
    "    if positive > negative:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f009e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tone_detect_word2vec(set_pos, set_neg, df_test):\n",
    "    results = []\n",
    "    origin = []\n",
    "    \n",
    "    for i, row in df_test.iterrows():\n",
    "        predicted_tone = pos_or_neg_word2vec(set_pos, set_neg, row['review'])\n",
    "        results.append(predicted_tone)\n",
    "\n",
    "        origin.append(row['grade'])\n",
    "\n",
    "    print(f'result: {accuracy_score(results, origin)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9bb91ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.65\n"
     ]
    }
   ],
   "source": [
    "test_tone_detect_word2vec(pos, neg, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3185a5a",
   "metadata": {},
   "source": [
    "Ну, это не получилось сделать прям улучшением алгоритма, но оно не сделало алгоритм хуже! Что тоже является успехом. Наверное, на большей выборке это могло бы сработать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08af8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
